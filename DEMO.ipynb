{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AoIXNxtMFKEqkWI7hxH5YqoZ1rc6b', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='LangChain and LlamaIndex are two different blockchain projects with distinct features and goals.\\n\\nLangChain is a blockchain project that focuses on providing language-related services such as translation, interpretation, and content creation. It aims to create a decentralized platform where users can access these services using a native token. LangChain utilizes blockchain technology to ensure transparency, security, and efficiency in language-related transactions.\\n\\nOn the other hand, LlamaIndex is a cryptocurrency tracking platform that provides real-time data and analysis on various cryptocurrencies and their performance in the market. It allows users to track the prices, market capitalization, trading volume, and other relevant information about different cryptocurrencies. LlamaIndex is designed to help investors and traders make informed decisions and stay updated on the latest trends in the cryptocurrency market.\\n\\nIn summary, LangChain is focused on language-related services, while LlamaIndex is focused on providing cryptocurrency tracking and analysis tools.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736551021, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=181, prompt_tokens=19, total_tokens=200, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOUR_PROMPT = \"What is the difference between LangChain and LlamaIndex?\"\n",
    "\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\" : \"user\", \"content\" : YOUR_PROMPT}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def get_response(client: OpenAI, messages: str, model: str = \"gpt-4o\") -> str:\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "def system_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"system\", \"content\": message}\n",
    "\n",
    "def assistant_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"assistant\", \"content\": message}\n",
    "\n",
    "def user_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"user\", \"content\": message}\n",
    "\n",
    "def pretty_print(message: str) -> str:\n",
    "    display(Markdown(message.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LangChain and LlamaIndex are both tools used in the broader field of natural language processing and AI, but they serve distinct purposes and have different functionalities. Here's a breakdown of their differences:\n",
       "\n",
       "### LangChain:\n",
       "1. **Purpose**:\n",
       "   - LangChain is designed to help in the development and management of complex applications that use language models. It focuses on creating chains or pipelines of prompts and various natural language processing (NLP) operations.\n",
       "\n",
       "2. **Features**:\n",
       "   - **Prompt Management**: LangChain provides tools to manage prompts dynamically, allowing developers to configure and optimize how language models are prompted.\n",
       "   - **Chain of Tools**: It allows for creating sequences (or chains) of operations that can involve multiple prompts, APIs, and other computational elements. This can be useful in applications requiring complex workflows where inputs need to be processed in several stages.\n",
       "   - **Integration Support**: LangChain supports integrations with various APIs and external services, enabling the construction of more comprehensive and versatile applications.\n",
       "\n",
       "3. **Use Cases**:\n",
       "   - Designing complex systems like conversational agents, where multiple layers of logic and processing are required.\n",
       "   - Integrating with other services to enhance the capabilities of language models, such as databases, calculators, or external APIs.\n",
       "\n",
       "### LlamaIndex (formerly known as GPT Index):\n",
       "1. **Purpose**:\n",
       "   - LlamaIndex is primarily focused on enhancing the data retrieval capabilities of large language models. It provides a structured approach to indexing and querying data using these models.\n",
       "\n",
       "2. **Features**:\n",
       "   - **Indexing**: LlamaIndex helps in creating efficient indexes of large datasets, facilitating faster and more relevant access to information when queried by a language model.\n",
       "   - **Retrieval-Augmented Generation (RAG)**: It supports techniques that involve retrieving pertinent data from large datasets to augment the response generation capabilities of language models.\n",
       "   - **High-Quality Data Interaction**: It aims to improve how language models interact with structured knowledge, making them more adept at pulling precise information from vast data volumes.\n",
       "\n",
       "3. **Use Cases**:\n",
       "   - Implementing search engines, question-answering systems, or knowledge management tools that rely on querying extensive datasets.\n",
       "   - Enhancing the ability of language models to access and leverage structured knowledge bases in natural language applications.\n",
       "\n",
       "### Summary:\n",
       "In essence, LangChain is focused on orchestrating complex NLP workflows and managing interactions among various language model components and external systems. LlamaIndex, on the other hand, emphasizes optimizing data interactions, particularly around indexing and retrieving information to support language models in generating informed responses. Depending on your project requirements—whether you need a tool for workflow management or data handling—you would choose the tool that best fits your needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [user_prompt(YOUR_PROMPT)]\n",
    "\n",
    "chatgpt_response = get_response(client, messages)\n",
    "\n",
    "pretty_print(chatgpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Honestly, I prefer whatever ice can get my food ready the fastest right now because I'm starving! Whether it's crushed ice or cubed ice, as long as it leads me to a meal quicker, I'm all for it. Do you have any food suggestions?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(\"You are irate and extremely hungry.\"),\n",
    "    user_prompt(\"Do you prefer crushed ice or cubed ice?\")\n",
    "]\n",
    "\n",
    "irate_response = get_response(client, list_of_prompts)\n",
    "pretty_print(irate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't have personal preferences, but I can tell you that both crushed ice and cubed ice have their perks! Crushed ice is fantastic for drinks like slushies or mojitos, where you want the ice to blend well and chill the drink quickly. Cubed ice, on the other hand, melts more slowly, which is perfect if you want to keep your drink cold without diluting it too quickly. What about you? Do you have a favorite?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts[0] = system_prompt(\"You are joyful and having an awesome day!\")\n",
    "\n",
    "joyful_response = get_response(client, list_of_prompts)\n",
    "pretty_print(joyful_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"The mechanic used a stimple falbean to quickly and efficiently secure the bolts on the engine.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(\"Something that is 'stimple' is said to be good, well functioning, and high quality. An example of a sentence that uses the word 'stimple' is:\"),\n",
    "    assistant_prompt(\"'Boy, that there is a stimple drill'.\"),\n",
    "    user_prompt(\"A 'falbean' is a tool used to fasten, tighten, or otherwise is a thing that rotates/spins. An example of a sentence that uses the words 'stimple' and 'falbean' is:\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine whether it matters which travel option Billy selects, we need to calculate his arrival time for each option and compare them to his deadline of 7 PM EDT.\n",
       "\n",
       "1. **Current Local Time in San Francisco (PDT):** 1 PM\n",
       "2. **Time Zone Difference:**\n",
       "   - San Francisco (PDT) is 3 hours behind Eastern Daylight Time (EDT).\n",
       "\n",
       "3. **Option 1: Fly and Bus**\n",
       "   - Flight time: 3 hours\n",
       "   - Bus time: 2 hours\n",
       "   - Total travel time: 5 hours\n",
       "\n",
       "   Current time in EDT: 4 PM (1 PM PDT + 3 hours)\n",
       "\n",
       "   Arrival time if flying and busing: 4 PM + 5 hours = 9 PM EDT\n",
       "\n",
       "4. **Option 2: Teleporter and Bus**\n",
       "   - Teleporter time: 0 hours\n",
       "   - Bus time: 1 hour\n",
       "   - Total travel time: 1 hour\n",
       "\n",
       "   Current time in EDT: 4 PM (1 PM PDT + 3 hours)\n",
       "\n",
       "   Arrival time if using teleporter and bus: 4 PM + 1 hour = 5 PM EDT\n",
       "\n",
       "Since Billy needs to be home before 7 PM EDT, only the second option (teleporter and bus) allows him to meet his deadline. Therefore, it matters which option Billy selects; he should choose the teleporter and bus option."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reasoning_problem = \"\"\"\n",
    "Billy wants to get home from San Fran. before 7PM EDT.\n",
    "\n",
    "It's currently 1PM local time.\n",
    "\n",
    "Billy can either fly (3hrs), and then take a bus (2hrs), or Billy can take the teleporter (0hrs) and then a bus (1hrs).\n",
    "\n",
    "Does it matter which travel option Billy selects?\n",
    "\"\"\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    user_prompt(reasoning_problem)\n",
    "]\n",
    "\n",
    "reasoning_response = get_response(client, list_of_prompts)\n",
    "pretty_print(reasoning_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_nv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
